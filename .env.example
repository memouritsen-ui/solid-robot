# Research Tool Environment Configuration
# Copy this file to .env and fill in your values

# ===================
# REQUIRED API KEYS
# ===================

# Tavily Search API (primary web search)
# Get key at: https://tavily.com
TAVILY_API_KEY=

# ===================
# OPTIONAL API KEYS
# ===================

# Anthropic Claude API (for cloud-best model)
# Get key at: https://console.anthropic.com
ANTHROPIC_API_KEY=

# Exa AI Search
# Get key at: https://exa.ai
EXA_API_KEY=

# Brave Search API
# Get key at: https://brave.com/search/api
BRAVE_API_KEY=

# Semantic Scholar (optional, free tier available)
# Get key at: https://api.semanticscholar.org
SEMANTIC_SCHOLAR_API_KEY=

# ===================
# OLLAMA CONFIGURATION
# ===================

# Ollama API base URL (default for local)
OLLAMA_BASE_URL=http://localhost:11434

# Number of parallel requests (recommend 4 for M4 Max)
OLLAMA_NUM_PARALLEL=4

# ===================
# SERVER CONFIGURATION
# ===================

# Backend server host
HOST=127.0.0.1

# Backend server port
PORT=8000

# Debug mode (set to true for development)
DEBUG=false

# ===================
# DATA PATHS
# ===================

# Directory for database files
DATA_DIR=./data

# ===================
# NOTES
# ===================
# 
# Minimum required: TAVILY_API_KEY
# 
# For cloud models: Add ANTHROPIC_API_KEY
# 
# For best coverage: Add all optional keys
# 
# Privacy mode "local_only" requires no API keys
# but needs Ollama running with models pulled:
#   ollama pull qwen2.5:32b-instruct-q5_K_M
#   ollama pull llama3.1:8b-instruct-q8_0
